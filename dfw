Write a python program that takes three command-line arguments: the paths to two files and the name of a hash algorithm (as shown in slide 2 of Class 6 on 6 Sept. 2024 ). 
The program will compare the contents of the two files by hashing them and checking if the hashes are the same.

import subprocess

import sys

def hash(f,fe):

   result=subprocess.run([fe,f],stdout=subprocess.PIPE,text=True)

   return result.stdout.split()[0]

f1=sys.argv[1]

f2=sys.argv[2]

name=sys.argv[3]

f3=hash(f1,name)

f4=hash(f2,name)

if(f3==f4):

   pint("equal")

else:

   print("not equal")
Read all the available file name of given directory (passed from command line argument) 
in python array and send the file names one by one to dd. Check attachment for the required python functions


import argparse

import os

import subprocess

parser = argparse.ArgumentParser(description="REcovery using foremost")

parser.add_argument("input_dir", type=str, help="Input directory")

parser.add_argument("output_dir", type=str, help="Output directory")

parser.add_argument("file_type", type=str, help="type of file")

args = parser.parse_args()

file_names=os.listdir(args.input_dir)

file_names=[file for file in file_names if os.path.isfile(os.path.join(args.input_dir,file))]

print(file_names)

for i in file_names:

   input=f"{args.input_dir}/{i}"

   command=f"foremost -i {input} -o {args.output_dir} -t {args.file_type}"

   subprocess.call(command,shell=True)

   print("foremost completed")


Develop a python code which takes 3 command line arguments (i)
input directory path (ii) output directory path (iii) type of file (jpg, pdf
etc) you can extract. Use arg parse to check rules of command line
argument.

import argparse

import os

import subprocess

import threading





def run_foremost(img,out,filetype):

   command=f"foremost -i {img} -o {out} -t {filetype}"

   subprocess.call(command,shell=True)

   print("foremost completed")





parser = argparse.ArgumentParser(description="REcovery using foremost")

parser.add_argument("input_dir", type=str, help="Input directory")

parser.add_argument("output_dir", type=str, help="Output directory")

parser.add_argument("file_type", type=str, help="type of file")

args = parser.parse_args()

file_names=os.listdir(args.input_dir)

file_names=[file for file in file_names if os.path.isfile(os.path.join(args.input_dir,file))]

print(file_names)

thread=["thread0","thread1"]

for j in range(6):

   start_time=time.time()

   for t in range(10000000):

      pass



   for i in range(len(file_names)):

      img=f"{args.input_dir}/{file_names[i]}"

      out=f"{args.output_dir}{file_names[i]}{j}"

      thread[i]=threading.Thread(target=run_foremost,args=(img,out,args.file_type))

      thread[i].start()

      print("Main thread continues to run...")

      thread[i].join()

      print("Thread finished, main thread ends.")

  
Develop a Python program that runs bulk_extractor on a list of input image files stored in a Python array, 
where the images are sourced from the directory path specified in the first command-line argument (input directory path).
The output directories generated by bulk_extractor should be stored in the directory path provided as the second command-line argument (output directory path). 
The third command-line argument specifies the number of threads to be used by bulk_extractor.
The sub process command are shown in attachment.

import argparse

import os

import subprocess

import threading

import time



def run_bulkextractor(img,out,noo):

   command=f"bulk_extractor -o {out} -j {noo} {img}"

   print(command)

   subprocess.call(command,shell=True)

   print("Bulk Extractor completed completed")



parser = argparse.ArgumentParser(description="REcovery using foremost")

parser.add_argument("input_dir", type=str, help="Input directory")

parser.add_argument("output_dir", type=str, help="Output directory")

parser.add_argument("noo", type=int, help="noo")

args = parser.parse_args()

file_names=os.listdir(args.input_dir)

file_names=[file for file in file_names if os.path.isfile(os.path.join(args.input_dir,file))]

print(file_names)

thread=[]

for j in range(args.noo):

   thread.append(f"threads{j}")



for i in range(len(file_names)):

      img=f"{args.input_dir}/{file_names[i]}"

      out=f"{args.output_dir}{file_names[i]}"

      thread[i]=threading.Thread(target=run_bulkextractor,args=(img,out,args.noo))

      thread[i].start()

      print("Main thread continues to run...")

      thread[i].join()

      print("Thread finished, main thread ends.")

Develop a python code to scan your subnet using nmap. Parse the IP Addresses, MAC Addresses and status of the Port Addresses using this python code in a csv file.
Modify the code to scan multiple ports like 22, 80, 81, 135, 139, 445, 1433. Submit only the python code.

import subprocess

import re

import csv



def scan_ip_mac_and_ports_status(network_range, ports=[80, 443, 22, 81, 135, 139, 445, 1433]):

   try:

       # Convert ports list to a comma-separated string

       ports_str = ",".join(map(str, ports))



       # Run the nmap command to scan IP, MAC, and port statuses

       result = subprocess.run(

           ["sudo", "nmap", "-sV", "-p", ports_str, network_range],

           stdout=subprocess.PIPE,

           stderr=subprocess.PIPE,

           text=True

       )



       if result.returncode != 0:

           print("Error running nmap:", result.stderr)

           return []



       # Regex patterns

       ip_regex = r"Nmap scan report for ([0-9]+\.[0-9]+\.[0-9]+\.[0-9]+)"

       mac_regex = r"MAC Address: ([0-9A-Fa-f:]+)"

       port_regex = r"(\d+)/tcp\s+(\w+)\s+([\w\s/.-]+)" # Port, status, service



       devices = []

       ip_address = None

       mac_address = None

       port_details = {str(port): {"Status": "not found", "Service": "not found"} for port in ports}



       # Parse the nmap output

       for line in result.stdout.splitlines():

           ip_match = re.search(ip_regex, line)

           mac_match = re.search(mac_regex, line)

           port_match = re.search(port_regex, line)



           if ip_match:

               # Save the previous IP's data before processing the next IP

               if ip_address:

                   for port, details in port_details.items():

                       devices.append({

                           "IP": ip_address,

                           "MAC": mac_address if mac_address else "Unknown",

                           "Port": port,

                           "Status": details["Status"],

                           "Service": details["Service"]

                       })

               # Start processing a new IP

               ip_address = ip_match.group(1)

               mac_address = None

               port_details = {str(port): {"Status": "not found", "Service": "not found"} for port in ports}



           if mac_match:

               mac_address = mac_match.group(1)



           if port_match and ip_address:

               port = port_match.group(1)

               status = port_match.group(2)

               service = port_match.group(3)

               port_details[port] = {"Status": status, "Service": service}



       # Append the last IP's data

       if ip_address:

           for port, details in port_details.items():

               devices.append({

                   "IP": ip_address,

                   "MAC": mac_address if mac_address else "Unknown",

                   "Port": port,

                   "Status": details["Status"],

                   "Service": details["Service"]

               })



       return devices



   except Exception as e:

       print("An error occurred:", str(e))

       return []



def writecsv(devices, filename):

   # Open the CSV file for writing

   with open(filename, mode='w', newline='') as file:

       # Define the fieldnames for the CSV file

       fieldnames = ["IP", "MAC", "Port", "Status", "Service"]

       writer = csv.DictWriter(file, fieldnames=fieldnames)



       # Write the header

       writer.writeheader()



       # Write the data for each device

       for device in devices:

           writer.writerow(device)

Develop a Python program that takes four command-line arguments:(1)The name of the tool (foremost or scalpel), (2)The input file path, 
(3)The output directory path and (4)The location of the configuration file.This Python program should run both scalpel and foremost on 
the specified input file (the 2nd command-line argument) using the configuration file (the 4th command-line argument). The output from 
both tools should be stored in the directory specified by the output directory path (the 3rd command-line argument).

import argparse

import os

import subprocess





def run_foremost(input_dir,output_dir,conf):

   command=f"foremost -i {input_dir} -o {output_dir} -c {conf}"

   print(command)

   subprocess.call(command,shell=True)

   print("Foremost completed completed")



def run_scalpel(input_dir,output_dir,conf):

   command=f"sudo scalpel -o {output_dir} {input_dir} -c {conf}"

   print(command)

   subprocess.call(command,shell=True)

   print("Scalpel completed completed")



parser = argparse.ArgumentParser(description="REcovery using foremost and scalpel")

parser.add_argument("Name",type=str,help="Tool name")

parser.add_argument("input_dir", type=str, help="Input directory")

parser.add_argument("output_dir", type=str, help="Output directory")

parser.add_argument("conf", type=str, help="conf")

args = parser.parse_args()



if args.Name=="foremost":

   run_foremost(args.input_dir,args.output_dir,args.conf)

elif args.Name=="scalpel":

   run_scalpel(args.input_dir,args.output_dir,args.conf)

else:

   print("error")


 Develop a Python program that takes four command-line arguments : (1)The name of the tool (foremost or magicrescue), (2)The input file path,
(3)The output directory path and (4)The type of file(s) to be carved. This Python program should run both magicrescue and foremost on the specified 
input file (the 2nd command-line argument) using the type of file(s) to be recovered (the 4th command-line argument).
The output from both tools should be stored in the directory specified by the output directory path (the 3rd command-line argument).


import argparse

import os

import subprocess





def run_foremost(input_dir,output_dir,typee):

   command=f"foremost -i {input_dir} -o {output_dir} -t {typee}"

   print(command)

   subprocess.call(command,shell=True)

   print("Foremost completed completed")



def run_magicrescue(input_dir,output_dir,typee):

   command=f"sudo magicrescue -r {typee} -d {output_dir} {input_dir}"

   print(command)

   subprocess.call(command,shell=True)

   print("magicrescue completed completed")



parser = argparse.ArgumentParser(description="REcovery using foremost and magicrescue")

parser.add_argument("Name",type=str,help="Tool name")

parser.add_argument("input_dir", type=str, help="Input directory")

parser.add_argument("output_dir", type=str, help="Output directory")

parser.add_argument("typee", type=str, help="typee")

args = parser.parse_args()



if args.Name=="foremost":

   run_foremost(args.input_dir,args.output_dir,args.typee)

elif args.Name=="magicrescue":

   run_magicrescue(args.input_dir,args.output_dir,args.typee)

else:

   print("errorb")


  Download the memory dump file of the Bundes Trojan (0zapftis) from the links provided in the attachment. 
  Carefully extract the file using unrar in a KALI environment, taking proper precautions. Run and save the
  output of the pslist and psxview plugins on the 0zapftis.vmem file. Then,develop a Python program to compare 
  the output files from pslist and psxview, identifying any hidden processes in the 0zapftis.vmem file by comparing 
  the PID and PPID values.

file1=open("/home/kalilinux/Desktop/pslist1","r")

file2=open("/home/kalilinux/Desktop/psxview1","r")



def uniquelist(file):

   uni=[]

   for line in file:

      columns=line.split()

      try:

         if isinstance(int(columns[0]),int) and isinstance(int(columns[1]),int):

            pid=int(columns[0])

            ppid=int(columns[1])

            uni.append(pid)

            uni.append(ppid)

      except:

         continue

   uni1=list(set(uni))

   return uni1

def uniqueview(file):

   uni=[]

   for line in file:

      try:

         columns=line.split()

         if isinstance(int(columns[2]),int):

            pid=int(columns[2])   

            uni.append(pid)



      except:

         continue

   uni1=list(set(uni))

   return uni1



file1arr=uniquelist(file1)

file2arr=uniqueview(file2)

print(file1arr)

print(file2arr)

hidden=[]

for i in file2arr:

   if i not in file1arr:

      hidden.append(i)

      print(i)

   else:

      continue

print(hidden)


Read network traffic at the wired interface of your computer using p0f for at least 5 minutes. Investigate the content of the log file generated from p0f command. 
Count (i)number of unique servers and clients.
(ii)Find unique server-client communication
(iii) number of unique server ports and client ports. 
(iv) Find most recent packet 
(v) find oldest packet


def logfile(filepath):

       clientsip = []

       serversip = []

       clientports = []

       serverports = []

       timestamps = []



       file=open(filepath,"r")

       for i in file:



           timestamp = i.split(" ")[0].strip('[]')

           print(timestamp)

           timestamps.append(timestamp)





           parts = i.split('|')



           client = None

           server = None

           clientport = None

           serverport = None





           for j in parts:

               if 'cli=' in j:

                   c = j.split('=')[1]

                   client = c.split('/')[0]

                   clientport = c.split('/')[1]

               elif 'srv=' in j:

                   s = j.split('=')[1]

                   server = s.split('/')[0]

                   serverport = s.split('/')[1]





           if client:

               clientsip.append(client)

               clientports.append(clientport)

           if server:

               serversip.append(server)

               serverports.append(serverport)





       print(clientsip)

       print(serversip)

       print(clientports)

       print(serverports)

       print(timestamps)

       uniqueclients= list(set(clientsip))

       uniqueservers= list(set(serversip))

       uniqueclientports=list(set(clientports))

       uniqueserverports=list(set(serverports))

       print(uniqueclients)

       print(uniqueservers)

       print(uniqueclientports)

       print(uniqueserverports)

       newpacket=max(timestamps)

       oldpacket=min(timestamps)

       print(newpacket)

       print(oldpacket)





file = "/home/kalilinux/Downloads/p0f.log"

logfile(file)

Capture network packets in a PCAP file using Scapy in a Python environment.
Develop Python code to identify anomalies in the given packets inside the PCAP file based on the following rules:
Rule 1: Common destination ports for TCP and UDP.
Rule 2: Excessive Traffic (DDoS).
Rule 3: Number of packets and packet size.
Rule 4: Unsolicited ARP replies.
Rule 5: Unusually large DNS responses.
Rule 6: Excessive ICMP Echo requests.
Rule 7: Excessive TCP SYN.
Rule 8: IPs scans excessive ports.
Please find the attached file for further details. Kindly submit only the Python code, not the PCAP file.

import csv

from collections import defaultdict

from scapy.all import rdpcap, TCP, UDP, ICMP, ARP, DNS, IP, Ether



# Constants for thresholds

TRAFFIC_THRESHOLD = 100

MTU_THRESHOLD = 1500

DNS_SIZE_THRESHOLD = 512

ICMP_ECHO_LIMIT = 50

SYN_THRESHOLD = 50

PORT_SCAN_THRESHOLD = 5



# File paths

PCAP_FILE = "project.pcap"

OUTPUT_FILE = "device_analysis.csv"



# Data structures for tracking metrics

ip_metrics = defaultdict(lambda: {

    "traffic": 0,

    "icmp_requests": 0,

    "syn_count": 0,

    "ports": set(),

    "mac": None,

    "oversized": 0,

    "dns_violation": 0

})

arp_cache = {}



# Functions to apply rules



def analyze_traffic(ip):

    """Detects high traffic from a single IP."""

    return int(ip_metrics[ip]["traffic"] > TRAFFIC_THRESHOLD)



def analyze_icmp(ip):

    """Checks for excessive ICMP echo requests."""

    return int(ip_metrics[ip]["icmp_requests"] > ICMP_ECHO_LIMIT)



def analyze_syn(ip):

    """Detects SYN flood behavior."""

    return int(ip_metrics[ip]["syn_count"] > SYN_THRESHOLD)



def analyze_ports(ip):

    """Identifies potential port scans."""

    return int(len(ip_metrics[ip]["ports"]) > PORT_SCAN_THRESHOLD)



def analyze_arp(packet):

    """Detects ARP conflicts."""

    if ARP in packet and packet[ARP].op == 2:  # ARP reply

        ip = packet[ARP].psrc

        mac = packet[ARP].hwsrc

        if ip in arp_cache and arp_cache[ip] != mac:

            return
